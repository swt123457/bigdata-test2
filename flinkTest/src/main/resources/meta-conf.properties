00001.source.topic=events_topic
00001.source.format=json
00001.source.schema=name:string,sex:string,age:int,job:map
00001.sink.topic=flink_topic
00001.sink.format=json
##00001.sink.schema=name:string,sex:string,age:int,job:string,offer:string
00001.sink.schema=name:string,sex:string,age:int
##00001.etl.sql=select name, sex, age, job['job'], job['offer'] from events_topic where age > 18
00001.etl.sql=select name, sex, (age + 100) as age from events_topic


00002.source.topic=events_topic
00002.soure.ddl=\
create table src_table (\
    id VARCHAR\
   ,name VARCHAR\
   ,timestamp_str VARCHAR\
   ,type VARCHAR\
   ,body map<varchar, varchar>\
)

00002.sink.topic=flink_topic

00002.sink.ddl=\
create table sink_table (\
 id  VARCHAR\
,name  VARCHAR\
,timestamp_str  VARCHAR\
,type  VARCHAR\
,appVersion  VARCHAR\
,behavior  VARCHAR\
,deviceId  VARCHAR\
,userId  string\
,userName  VARCHAR\
)

00002.etl.dml=select id,name,timestamp_str,type,body['appVersion'],body['behavior'],body['deviceId'],body['userId'],body['userName'] from src_table

test.topicName=bigdata_app-mysql_stream_test
test.sinkTable=test.mysql_stream_test
test.keys=task_rule_id,assign_batch_no,month,assign_mode,assign_by,assign_by_id,status,rowkey

uat.flink.parallelism=8

uat.ck.user=writer
uat.ck.password=123456
uat.ck.batchSize=50
uat.ck.batchIntervalMs=10
